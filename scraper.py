import requests
from bs4 import BeautifulSoup
import os
import sys
import time
import shutil

# --- MOTOR: DrissionPage ---
from DrissionPage import ChromiumPage, ChromiumOptions

# --- BEÃLLÃTÃSOK ---
TOKEN = os.environ.get('TELEGRAM_TOKEN')
CHAT_ID = os.environ.get('TELEGRAM_CHAT_ID')
SEEN_FILE = "seen_ads.txt"
KEYWORDS_FILE = "keywords.txt"

# URL-ek
URL_HA = "https://hardverapro.hu/aprok/pc_szerver/apple_mac_imac/mac_mini/index.html"
URL_MSZ = "https://www.menemszol.hu/aprohirdetes/page/1"

# --- KÃ–ZÃ–S SEGÃ‰DFÃœGGVÃ‰NYEK ---

def send_telegram(message):
    if not TOKEN or not CHAT_ID:
        print("Hiba: Nincs beÃ¡llÃ­tva TELEGRAM_TOKEN vagy TELEGRAM_CHAT_ID")
        return
    url = f"https://api.telegram.org/bot{TOKEN}/sendMessage"
    payload = {"chat_id": CHAT_ID, "text": message}
    try:
        requests.post(url, json=payload)
    except Exception as e:
        print(f"Hiba Ã¼zenetkÃ¼ldÃ©skor: {e}")

def load_seen_ads():
    if not os.path.exists(SEEN_FILE):
        return set()
    with open(SEEN_FILE, "r") as f:
        return set(line.strip() for line in f)

def save_seen_ad(ad_url):
    with open(SEEN_FILE, "a") as f:
        f.write(ad_url + "\n")

def load_keywords_by_site():
    """
    Beolvassa a keywords.txt-t Ã©s szÃ©tvÃ¡logatja a szavakat.
    """
    keywords = {
        "hardverapro": [],
        "menemszol": []
    }
    
    defaults = {
        "hardverapro": ["mac mini"],
        "menemszol": ["elektron", "access", "virus", "focusrite"]
    }

    if not os.path.exists(KEYWORDS_FILE):
        print("âš ï¸ Nem talÃ¡lhatÃ³ a keywords.txt, alapÃ©rtelmezett szavakat hasznÃ¡lom.")
        return defaults
    
    try:
        current_section = None
        with open(KEYWORDS_FILE, "r", encoding="utf-8") as f:
            for line in f:
                line = line.strip()
                if not line: continue
                
                if line.upper() == "[HARDVERAPRO]":
                    current_section = "hardverapro"
                    continue
                elif line.upper() == "[MENEMSZOL]":
                    current_section = "menemszol"
                    continue
                
                if current_section in keywords:
                    keywords[current_section].append(line.lower())
        
        # Ha valamelyik Ã¼res maradt, tÃ¶ltsÃ¼k fel az alappal
        if not keywords["hardverapro"]: keywords["hardverapro"] = defaults["hardverapro"]
        if not keywords["menemszol"]: keywords["menemszol"] = defaults["menemszol"]
            
        print(f"ðŸ“‹ HardverAprÃ³ szavak: {keywords['hardverapro']}")
        print(f"ðŸ“‹ Menemszol szavak: {keywords['menemszol']}")
        return keywords

    except Exception as e:
        print(f"Hiba a kulcsszavak olvasÃ¡sakor: {e}")
        return defaults

# --- 1. HARDVERAPRÃ“ SCRAPER ---

def scrape_hardverapro(seen_ads, keywords):
    print("--- HardverAprÃ³ ellenÅ‘rzÃ©se ---")
    ha_headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        "Referer": "https://hardverapro.hu/"
    }
    try:
        response = requests.get(URL_HA, headers=ha_headers)
        response.raise_for_status()
        soup = BeautifulSoup(response.content, 'html.parser')
        ads = soup.find_all('li', class_='media')
        new_count = 0
        
        for ad in ads:
            title_div = ad.find('div', class_='uad-col-title')
            if not title_div: continue
            link_tag = title_div.find('a')
            if not link_tag: continue
            
            title = link_tag.get_text().strip()
            link = link_tag['href']
            full_link = link if link.startswith("http") else f"https://hardverapro.hu{link}"
            
            price_div = ad.find('div', class_='uad-price')
            price = price_div.get_text().strip() if price_div else "Nincs Ã¡r"

            if not any(word in title.lower() for word in keywords):
                continue

            if full_link in seen_ads: continue 
            
            print(f"Ãšj HA talÃ¡lat: {title}")
            msg = f"ðŸŽ Ãšj Mac Mini hirdetÃ©s!\n\n**{title}**\nÃr: {price}\n\nLink: {full_link}"
            send_telegram(msg)
            save_seen_ad(full_link)
            seen_ads.add(full_link)
            new_count += 1
            
        print(f"HA vÃ©ge. {new_count} Ãºj hirdetÃ©s.")
    except Exception as e:
        print(f"HIBA a HardverAprÃ³nÃ¡l: {e}")

# --- 2. MENEMSZOL SCRAPER ---

def scrape_menemszol(seen_ads, keywords):
    print("--- Menemszol.hu ellenÅ‘rzÃ©se ---")
    
    page = None
    
    try:
        print("BÃ¶ngÃ©szÅ‘ konfigurÃ¡lÃ¡sa...")
        co = ChromiumOptions()
        co.set_argument('--no-sandbox')
        co.set_argument('--headless=new')
        co.set_argument('--disable-gpu')
        co.set_user_agent('Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36')

        chrome_path = shutil.which("google-chrome") or shutil.which("chrome") or shutil.which("chromium")
        if chrome_path:
             co.set_paths(browser_path=chrome_path)

        page = ChromiumPage(co)
        print(f"Link megnyitÃ¡sa: {URL_MSZ}")
        page.get(URL_MSZ)
        
        # --- CLOUDFLARE KEZELÃ‰S ---
        
        if "Verify" in page.title or "Just a moment" in page.title:
            print("âš ï¸ Cloudflare gyanÃº! MegoldÃ¡s indÃ­tÃ¡sa...")
            try:
                # Csak akkor vÃ¡runk, ha tÃ©nyleg baj van
                time.sleep(2) 
                cf_box = page.ele('@id=challenge-stage', timeout=2)
                if cf_box: cf_box.click() 
                verify_text = page.ele('text:Verify you are human', timeout=2)
                if verify_text: verify_text.click()
                
                # Ha kattintottunk, akkor viszont kell idÅ‘ a betÃ¶ltÃ©shez
                print("KattintÃ¡s tÃ¶rtÃ©nt, vÃ¡rakozÃ¡s...")
                time.sleep(5) 
            except: pass

        if "Just a moment" in page.title:
             print(f"âŒ Cloudflare blokkol.")
        else:
            print("âœ… Sikeresen betÃ¶ltve!")
            
            soup = BeautifulSoup(page.html, 'html.parser')
            all_links = soup.find_all('a', href=True)
            print(f"  -> Az oldalon Ã¶sszesen {len(all_links)} db link van.")
            
            new_count = 0
            
            for link in all_links:
                href = link['href']
                text = link.get_text(" ", strip=True)
                
                # --- SZÅ°RÃ‰S ---
                if "/aprohirdetes/" not in href: continue
                
                ignore_list = ["/category/", "/page/", "?sort", "&sort", "do=markRead", "/profile/"]
                if any(x in href for x in ignore_list): continue
                
                if not text or len(text) < 3: continue

                # KULCSSZÃ“ KERESÃ‰S (A beadott keywords listÃ¡bÃ³l)
                if not any(word in text.lower() for word in keywords): continue

                # DUPLIKÃCIÃ“ SZÅ°RÃ‰S
                if href in seen_ads: continue

                print(f"Ãšj Menemszol talÃ¡lat: {text}")
                msg = f"ðŸŽ¹ TALÃLAT (Menemszol)!\n\n**{text}**\n\nLink: {href}"
                send_telegram(msg)
                
                save_seen_ad(href)
                seen_ads.add(href)
                new_count += 1
            
            print(f"Menemszol vÃ©ge. {new_count} Ãºj hirdetÃ©s.")

    except Exception as e:
        print(f"KRITIKUS HIBA a MenemszolnÃ¡l: {e}")
    finally:
        if page:
            try:
                page.quit()
                print("B
