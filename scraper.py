import requests
from bs4 import BeautifulSoup
import os
import sys
import time
import shutil

# --- MOTOR: DrissionPage ---
from DrissionPage import ChromiumPage, ChromiumOptions

# --- BEÃLLÃTÃSOK ---
TOKEN = os.environ.get('TELEGRAM_TOKEN')
CHAT_ID = os.environ.get('TELEGRAM_CHAT_ID')
SEEN_FILE = "seen_ads.txt"
KEYWORDS_FILE = "keywords.txt"

# ðŸ¤« CSENDES MÃ“D
# Ha Ãºj kulcsszÃ³t adsz hozzÃ¡, Ã¡llÃ­tsd ezt True-ra egy kÃ¶r erejÃ©ig!
# True = Elmenti a talÃ¡latokat, de NEM kÃ¼ld Telegram Ã¼zenetet.
# False = NormÃ¡l mÅ±kÃ¶dÃ©s, kÃ¼ld Ã¼zenetet.
SILENT_MODE = True 

# URL-ek
URL_HA_SEARCH_BASE = "https://hardverapro.hu/aprok/keres.php?order=1&stext="
URL_MSZ = "https://www.menemszol.hu/aprohirdetes/page/1"

# --- KÃ–ZÃ–S SEGÃ‰DFÃœGGVÃ‰NYEK ---

def send_telegram(message):
    # Ha be van kapcsolva a Csendes MÃ³d, akkor itt kilÃ©pÃ¼nk kÃ¼ldÃ©s nÃ©lkÃ¼l
    if SILENT_MODE:
        print("ðŸ¤« Csendes mÃ³d aktÃ­v: Ãœzenet kihagyva.")
        return

    if not TOKEN or not CHAT_ID:
        print("Hiba: Nincs beÃ¡llÃ­tva TELEGRAM_TOKEN vagy TELEGRAM_CHAT_ID")
        return
    url = f"https://api.telegram.org/bot{TOKEN}/sendMessage"
    payload = {"chat_id": CHAT_ID, "text": message}
    try:
        requests.post(url, json=payload)
    except Exception as e:
        print(f"Hiba Ã¼zenetkÃ¼ldÃ©skor: {e}")

def load_seen_ads():
    if not os.path.exists(SEEN_FILE):
        return set()
    with open(SEEN_FILE, "r") as f:
        return set(line.strip() for line in f)

def save_seen_ad(ad_url):
    with open(SEEN_FILE, "a") as f:
        f.write(ad_url + "\n")

def load_keywords_by_site():
    """
    Beolvassa a keywords.txt-t Ã©s szÃ©tvÃ¡logatja a szavakat.
    """
    keywords = {
        "hardverapro": [],
        "menemszol": []
    }
    
    defaults = {
        "hardverapro": ["mac mini"],
        "menemszol": ["elektron", "access", "virus", "focusrite"]
    }

    if not os.path.exists(KEYWORDS_FILE):
        print("âš ï¸ Nem talÃ¡lhatÃ³ a keywords.txt, alapÃ©rtelmezett szavakat hasznÃ¡lom.")
        return defaults
    
    try:
        current_section = None
        with open(KEYWORDS_FILE, "r", encoding="utf-8") as f:
            for line in f:
                line = line.strip()
                if not line: continue
                
                if line.upper() == "[HARDVERAPRO]":
                    current_section = "hardverapro"
                    continue
                elif line.upper() == "[MENEMSZOL]":
                    current_section = "menemszol"
                    continue
                
                if current_section in keywords:
                    keywords[current_section].append(line.lower())
        
        if not keywords["hardverapro"]: keywords["hardverapro"] = defaults["hardverapro"]
        if not keywords["menemszol"]: keywords["menemszol"] = defaults["menemszol"]
            
        return keywords

    except Exception as e:
        print(f"Hiba a kulcsszavak olvasÃ¡sakor: {e}")
        return defaults

# --- 1. HARDVERAPRÃ“ SCRAPER ---

def scrape_hardverapro(seen_ads, keywords):
    print("--- HardverAprÃ³ ellenÅ‘rzÃ©se ---")
    
    ha_headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        "Referer": "https://hardverapro.hu/"
    }

    for keyword in keywords:
        search_term = f'"{keyword}"'
        print(f"ðŸ”Ž KeresÃ©s erre: {search_term}...")
        
        search_url = f"{URL_HA_SEARCH_BASE}{search_term}"
        
        try:
            response = requests.get(search_url, headers=ha_headers)
            response.raise_for_status()
            soup = BeautifulSoup(response.content, 'html.parser')
            
            ads = soup.find_all('li', class_='media')
            new_count = 0
            
            for ad in ads:
                title_div = ad.find('div', class_='uad-col-title')
                if not title_div: continue
                link_tag = title_div.find('a')
                if not link_tag: continue
                
                title = link_tag.get_text().strip()
                link = link_tag['href']
                full_link = link if link.startswith("http") else f"https://hardverapro.hu{link}"
                
                price_div = ad.find('div', class_='uad-price')
                price = price_div.get_text().strip() if price_div else "Nincs Ã¡r"

                # CÃ­m ellenÅ‘rzÃ©s
                if keyword.lower() not in title.lower():
                    continue

                if full_link in seen_ads: continue 
                
                print(f"Ãšj HA talÃ¡lat: {title}")
                msg = f"ðŸŽ TALÃLAT (HardverAprÃ³ - {keyword})!\n\n**{title}**\nÃr: {price}\n\nLink: {full_link}"
                
                # Itt hÃ­vjuk meg a kÃ¼ldÃ©st (ami ellenÅ‘rzi a SILENT_MODE-ot)
                send_telegram(msg)
                
                # De a mentÃ©s MINDIG megtÃ¶rtÃ©nik!
                save_seen_ad(full_link)
                seen_ads.add(full_link)
                new_count += 1
            
            print(f"  -> {new_count} Ãºj talÃ¡lat ennÃ©l a szÃ³nÃ¡l.")
            time.sleep(2)

        except Exception as e:
            print(f"HIBA a HardverAprÃ³nÃ¡l ({keyword}): {e}")

# --- 2. MENEMSZOL SCRAPER ---

def scrape_menemszol(seen_ads, keywords):
    print("--- Menemszol.hu ellenÅ‘rzÃ©se ---")
    
    page = None
    
    try:
        print("BÃ¶ngÃ©szÅ‘ konfigurÃ¡lÃ¡sa...")
        co = ChromiumOptions()
        co.set_argument('--no-sandbox')
        co.set_argument('--headless=new')
        co.set_argument('--disable-gpu')
        co.set_user_agent('Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36')

        chrome_path = shutil.which("google-chrome") or shutil.which("chrome") or shutil.which("chromium")
        if chrome_path:
             co.set_paths(browser_path=chrome_path)

        page = ChromiumPage(co)
        print(f"Link megnyitÃ¡sa: {URL_MSZ}")
        page.get(URL_MSZ)
        
        # --- CLOUDFLARE ---
        if "Verify" in page.title or "Just a moment" in page.title:
            print("âš ï¸ Cloudflare gyanÃº! MegoldÃ¡s indÃ­tÃ¡sa...")
            try:
                time.sleep(2) 
                cf_box = page.ele('@id=challenge-stage', timeout=2)
                if cf_box: cf_box.click() 
                verify_text = page.ele('text:Verify you are human', timeout=2)
                if verify_text: verify_text.click()
                time.sleep(5) 
            except: pass

        if "Just a moment" in page.title:
             print(f"âŒ Cloudflare blokkol.")
        else:
            print("âœ… Sikeresen betÃ¶ltve!")
            
            soup = BeautifulSoup(page.html, 'html.parser')
            all_links = soup.find_all('a', href=True)
            print(f"  -> Az oldalon Ã¶sszesen {len(all_links)} db link van.")
            
            new_count = 0
            
            for link in all_links:
                href = link['href']
                text = link.get_text(" ", strip=True)
                
                if "/aprohirdetes/" not in href: continue
                ignore_list = ["/category/", "/page/", "?sort", "&sort", "do=markRead", "/profile/"]
                if any(x in href for x in ignore_list): continue
                if not text or len(text) < 3: continue

                if not any(word in text.lower() for word in keywords): continue
                if href in seen_ads: continue

                print(f"Ãšj Menemszol talÃ¡lat: {text}")
                msg = f"ðŸŽ¹ TALÃLAT (Menemszol)!\n\n**{text}**\n\nLink: {href}"
                
                send_telegram(msg)
                
                save_seen_ad(href)
                seen_ads.add(href)
                new_count += 1
            
            print(f"Menemszol vÃ©ge. {new_count} Ãºj hirdetÃ©s.")

    except Exception as e:
        print(f"KRITIKUS HIBA a MenemszolnÃ¡l: {e}")
    finally:
        if page:
            try:
                page.quit()
                print("BÃ¶ngÃ©szÅ‘ bezÃ¡rva.")
            except:
                pass

# --- FÅ PROGRAM ---

if __name__ == "__main__":
    seen_ads_memory = load_seen_ads()
    all_keywords = load_keywords_by_site()
    
    scrape_hardverapro(seen_ads_memory, all_keywords['hardverapro'])
    print("-" * 30)
    scrape_menemszol(seen_ads_memory, all_keywords['menemszol'])
